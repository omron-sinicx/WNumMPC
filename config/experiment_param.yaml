sim:
  human_num: 6  # the number of all agents = (human_num+1)
  robot_policy: "wnum_mpc"  # wnum_mpc / vanilla_mpc / mean_mpc (T-MPC)
  position:
    circle:
      r: 2.0
      rx: 1.5  # for creating a circle scenario (radius)
      ry: 1.5  # for creating a circle scenario (radius)
    rectangle:
      w: 6.0  # disable
    min_dist: 0.90
  time_limit: 30.0  # time limit for each episode
  done_if_all_agents_reached: True  # False if train CADRL

goal_threshold: 1.5
collision_radius: 0.2

eval_episodes: 100 # episodes for evaluation (30 is set when training)
plot_trajectory: False
plot_animation: False
animation_dir: ./plot_data/animation_normal_angle_cost/
save_trajectory: False
trajectory_dir: ./plot_data/animation_sim_normal_margin/
use_maru: False
use_maru_verbose: False
#eval_states: ./datas/eval_states/slow-7-100.npy
#eval_states: ./datas/eval_states/optuna-7-30.npy
#result_file: tmp.json
#result_file: ./datas/maru_results/slow-7-100-normal-margin.json

detect_collisions: True

# for optimization of hyperparameters
use_optuna: False
multi_thread: True
optuna_trials: 144


# for CADRL
cadrl:
  mlp_dims: [150, 100, 100, 1]
  multiagent_training: true


defaults:
  - _self_
  - params: default_param  # config.MPC.params
  - cadrl_param: default  # config for CADRL